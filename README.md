# deep-learning-challenge
- Module 21 Challenge 

# Neural Network Model Report: Alphabet Soup Deep Learning Analysis 
Overview of the Analysis
The purpose of this analysis was to develop and evaluate a deep learning model to predict whether a non-profit organization would receive funding from Alphabet Soup. By using historical data containing organizational, financial, and categorical attributes, the objective was to create a binary classification model that could assist in funding decisions.
 
## Results
Data Preprocessing
â€¢    Target Variable(s):
o    IS_SUCCESSFUL â€” indicates whether an organization received funding (1) or did not (0).
â€¢    Feature Variable(s):
o    Categorical and numerical variables related to the organization's activities and financial details, including:
ï‚§    APPLICATION_TYPE
ï‚§    AFFILIATION
ï‚§    ASK_AMT
ï‚§    INCOME_AMT
ï‚§    SPECIAL_CONSIDERATIONS
ï‚§    CLASSIFICATION
ï‚§    USE_CASE
ï‚§    ORGANIZATION
ï‚§    Encoded versions of other relevant categorical features using One-Hot Encoding.
â€¢    Variables Removed:
o    Columns removed due to irrelevance or potential data leakage:
ï‚§    EIN (Unique identifier)
ï‚§    NAME (Organization name)
ï‚§    STATUS (Post-target or duplicative)
ï‚§    Any other columns with excessive null values or unrelated to prediction
 
## Compiling, Training, and Evaluating the Model
â€¢    Neural Network Architecture:
o    Input Layer: Based on the number of input features after preprocessing (e.g., ~116 features after One-Hot Encoding).
o    Hidden Layers:
ï‚§    First hidden layer: 80 neurons, ReLU activation
ï‚§    Second hidden layer: 30 neurons, ReLU activation
ï‚§    Dropout layers (rate = 0.2) were added after hidden layers to reduce overfitting
o    Output Layer:
ï‚§    1 neuron with Sigmoid activation (for binary classification)
â€¢    Model Compilation:
o    Loss function: Binary Crossentropy
o    Optimizer: Adam (performed best during experimentation)
o    Metrics: Accuracy
â€¢    Model Performance:
o    âœ… Achieved approximately 73% accuracy on the validation set
o    ðŸ“‰ Training and validation loss both steadily decreased
o    ðŸ“ˆ Accuracy stabilized and generalization remained consistent after tuning


â€¢     Steps Taken to Improve Performance:
o    Performed feature scaling (standardization of ASK_AMT and other numeric features)
o    Applied One-Hot Encoding to categorical variables
o    Added Dropout layers to reduce overfitting
o    Tuned:
ï‚§    Number of neurons in each hidden layer
ï‚§    Batch size (32 vs 64)
ï‚§    Number of epochs (increased from 20 to 50)
ï‚§    Learning rate (via optimizer tweaking)
o    Compared multiple architectures and logged performance for each attempt
 
## Summary and Recommendations
The final deep learning model effectively predicts funding success with a validation accuracy of around 75%, meeting the project goal. This result demonstrates that neural networks can be a viable solution for binary classification problems involving structured tabular data, especially with thorough data preprocessing and model tuning.
Alternative Model Recommendation
To further improve performance or interpretability, I recommend experimenting with ensemble tree-based models such as:
â€¢    Random Forest Classifier
â€¢    Gradient Boosted Trees (e.g., XGBoost, LightGBM)
Why?
â€¢    These models:
o    Handle categorical features natively (with minimal encoding)
o    Are robust to overfitting due to ensemble averaging
o    Provide clear feature importance rankings, which are easier for stakeholders to interpret
o    Often outperform neural networks on small to mid-sized structured datasets
 

